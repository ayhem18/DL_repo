"""
This script contains a number of sanity check to make sure everything is working as expected

1. visualize the dataset
2. visualize the noisy images generated by adding the noise to the dataset

"""


import os
import torch
import albumentations as A

from pathlib import Path
from diffusers import DDPMScheduler
from torchvision import transforms as tr

from mypt.visualization.general import visualize
from mypt.data.dataloaders.standard_dataloaders import initialize_val_dataloader
from mypt.data.datasets.genericFolderDs import Food101GenericWrapper, MnistGenericWrapper


def visualize_wrapper():
    d = os.path.join(Path(__file__).parent, "data", "train")

    train_ds = MnistGenericWrapper(root_dir=d, 
                                   augmentations=None, 
                                   train=True, 
                                   samples_per_cls=3)
    
    print(len(train_ds))

    for i in range(len(train_ds)):
        visualize(train_ds[i])


def visualize_dataset():
    """
    consecutive samples are not fo the same class... not ideal..
    """

    d = os.path.join(Path(__file__).parent, "data", "train")

    train_ds = MnistGenericWrapper(root_dir=d, 
                                   augmentations=None, 
                                   train=True, 
                                   samples_per_cls=3)
    
    ds = train_ds._ds

    for i in range(20):
        visualize(ds[i][0])


from dataset.mnist import MnistDSWrapper


def visualize_noisy_images():
    d = os.path.join(Path(__file__).parent, "data", "train")


    # train_ds = MnistGenericWrapper(root_dir=d, 
    #                                augmentations=[tr.Resize(size=(256, 256))], 
    #                                train=True, 

    train_ds = MnistDSWrapper(root=d, 
                              train=True, 
                              transforms=[A.RandomResizedCrop(size=(128, 128), scale=(0.4, 1))], 
                              output_shape=(48, 48)
                              )

    # d2 = os.path.join(Path(__file__).parent, "data", "food101", "train")
    
    # train_ds = Food101GenericWrapper(root_dir=d2, 
    #                                augmentations=[tr.Resize(size=(512, 512))], 
    #                                train=True, 
    #                                samples_per_cls=3)

    loader = initialize_val_dataloader(train_ds, seed=0,batch_size=10, num_workers=0)

    # it might be crucial to set the beta_env to a low value so that the images wouldn't get too noisy too fast...
    # need to back up my intuition with some math / papers...
    noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule="linear", beta_end=0.001) 

    device = "cuda"

    for loader_batch in loader:
        batch, _, _ = loader_batch
        
        batch = batch.to(device)

        # process the batch

        batch = 2 * batch - 1

        noise = torch.randn(batch.shape, device=device)

        timesteps = torch.tensor([950] * batch.shape[0], device=device, dtype=torch.int64)

        # timesteps = torch.randint(
        #     0, noise_scheduler.config.num_train_timesteps, (batch.shape[0],), device=device,
        #     dtype=torch.int64
        # )
        
        noisy_images = noise_scheduler.add_noise(batch, noise, timesteps)

        # move the image back to the [0, 255] range
        noisy_images = (noisy_images + 1) * 127.5

        for img, t in zip(noisy_images, timesteps):
            visualize(img, window_name=f"Noisy Image at timestep {t}")

        # images = (batch + 1) * 127.5

        # for img in images[:5]:
        #     visualize(img)


if __name__ == "__main__":
    visualize_noisy_images()
 